#!/usr/bin/env python3
"""
Train a U-Net model for flood detection using change detection approach.

This script:
1. Loads pre-flood and post-flood image pairs
2. Uses ground truth masks generated by change detection
3. Trains a U-Net to predict flood masks from image pairs
4. Implements proper data augmentation and loss functions
5. Saves the trained model and training history

Usage:
    python train_flood_unet.py
"""

import os
import cv2
import numpy as np
import pandas as pd
from pathlib import Path
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import jaccard_score, precision_score, recall_score
import tensorflow as tf
from tensorflow.keras import layers, Model, optimizers, callbacks
from tensorflow.keras.utils import Sequence
import albumentations as A
from tqdm import tqdm

# Set random seeds for reproducibility
np.random.seed(42)
tf.random.set_seed(42)

# Configuration
IMAGE_SIZE = 256  # Resize images to this size
BATCH_SIZE = 8
EPOCHS = 50
LEARNING_RATE = 1e-4
VALIDATION_SPLIT = 0.2

# Directories
PREFLOOD_DIR = Path("preflood_dataset")
POSTFLOOD_DIR = Path("postflood_dataset")
MASKS_DIR = Path("ground_truth_masks")
MODELS_DIR = Path("trained_models")
LOGS_DIR = Path("training_logs")

# Create output directories
MODELS_DIR.mkdir(exist_ok=True)
LOGS_DIR.mkdir(exist_ok=True)

class FloodDataGenerator(Sequence):
    """Custom data generator for flood detection training."""
    
    def __init__(self, image_list, batch_size=BATCH_SIZE, image_size=IMAGE_SIZE, 
                 augment=True, shuffle=True):
        self.image_list = image_list
        self.batch_size = batch_size
        self.image_size = image_size
        self.augment = augment
        self.shuffle = shuffle
        self.indices = np.arange(len(self.image_list))
        
        # Data augmentation pipeline
        if self.augment:
            self.transform = A.Compose([
                A.HorizontalFlip(p=0.5),
                A.VerticalFlip(p=0.5),
                A.Rotate(limit=20, p=0.5),
                A.RandomBrightnessContrast(p=0.3),
                A.GaussNoise(p=0.3),
            ])
        else:
            self.transform = None
            
        self.on_epoch_end()
    
    def __len__(self):
        return int(np.ceil(len(self.image_list) / self.batch_size))
    
    def __getitem__(self, index):
        indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]
        batch_images = [self.image_list[k] for k in indices]
        
        X, y = self._generate_batch(batch_images)
        return X, y
    
    def on_epoch_end(self):
        if self.shuffle:
            np.random.shuffle(self.indices)
    
    def _generate_batch(self, batch_images):
        X = np.zeros((len(batch_images), self.image_size, self.image_size, 2), dtype=np.float32)
        for i, filename in enumerate(batch_images):
            # Load images
            pre_img = cv2.imread(str(PREFLOOD_DIR / filename), cv2.IMREAD_GRAYSCALE)
            post_img = cv2.imread(str(POSTFLOOD_DIR / filename), cv2.IMREAD_GRAYSCALE)
            # Resize images
            pre_img = cv2.resize(pre_img, (self.image_size, self.image_size))
            post_img = cv2.resize(post_img, (self.image_size, self.image_size))
            # Normalize images to [0, 1]
            pre_img = pre_img.astype(np.float32) / 255.0
            post_img = post_img.astype(np.float32) / 255.0
            # Apply augmentation
            if self.transform:
                combined = np.stack([pre_img, post_img], axis=-1)
                augmented = self.transform(image=combined)['image']
                pre_img = augmented[:, :, 0]
                post_img = augmented[:, :, 1]
            # Stack pre and post images as channels
            X[i, :, :, 0] = pre_img
            X[i, :, :, 1] = post_img
        return X, None

def build_unet(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 2)):
    """Build U-Net architecture for flood detection."""
    
    # Encoder (downsampling path)
    inputs = layers.Input(input_shape)
    
    # Block 1
    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)
    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c1)
    p1 = layers.MaxPooling2D((2, 2))(c1)
    
    # Block 2
    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(p1)
    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c2)
    p2 = layers.MaxPooling2D((2, 2))(c2)
    
    # Block 3
    c3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(p2)
    c3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c3)
    p3 = layers.MaxPooling2D((2, 2))(c3)
    
    # Block 4
    c4 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(p3)
    c4 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(c4)
    p4 = layers.MaxPooling2D((2, 2))(c4)
    
    # Bottleneck
    c5 = layers.Conv2D(1024, (3, 3), activation='relu', padding='same')(p4)
    c5 = layers.Conv2D(1024, (3, 3), activation='relu', padding='same')(c5)
    
    # Decoder (upsampling path)
    u6 = layers.Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(c5)
    u6 = layers.concatenate([u6, c4])
    c6 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(u6)
    c6 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(c6)
    
    u7 = layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c6)
    u7 = layers.concatenate([u7, c3])
    c7 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(u7)
    c7 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c7)
    
    u8 = layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c7)
    u8 = layers.concatenate([u8, c2])
    c8 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(u8)
    c8 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c8)
    
    u9 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c8)
    u9 = layers.concatenate([u9, c1])
    c9 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u9)
    c9 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c9)
    
    # Output layer
    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)
    
    model = Model(inputs=[inputs], outputs=[outputs])
    return model

def dice_coefficient(y_true, y_pred, smooth=1e-6):
    """Dice coefficient for evaluating segmentation performance."""
    y_true_f = tf.keras.backend.flatten(y_true)
    y_pred_f = tf.keras.backend.flatten(y_pred)
    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)
    return (2. * intersection + smooth) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + smooth)

def dice_loss(y_true, y_pred):
    """Dice loss function."""
    return 1 - dice_coefficient(y_true, y_pred)

def combined_loss(y_true, y_pred):
    """Combined Dice loss and Binary Cross Entropy."""
    bce = tf.keras.losses.binary_crossentropy(y_true, y_pred)
    dice = dice_loss(y_true, y_pred)
    return bce + dice

def evaluate_model(model, test_generator):
    """Evaluate model performance on test set."""
    y_true_all = []
    y_pred_all = []
    
    print("Evaluating model...")
    for i in tqdm(range(len(test_generator))):
        X_batch, y_batch = test_generator[i]
        y_pred_batch = model.predict(X_batch, verbose=0)
        
        # Convert to binary predictions
        y_pred_binary = (y_pred_batch > 0.5).astype(int)
        
        # Flatten for metrics calculation
        y_true_flat = y_batch.flatten()
        y_pred_flat = y_pred_binary.flatten()
        
        y_true_all.extend(y_true_flat)
        y_pred_all.extend(y_pred_flat)
    
    # Calculate metrics
    iou = jaccard_score(y_true_all, y_pred_all, average='binary')
    precision = precision_score(y_true_all, y_pred_all, average='binary')
    recall = recall_score(y_true_all, y_pred_all, average='binary')
    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
    
    return {
        'IoU': iou,
        'Precision': precision,
        'Recall': recall,
        'F1-Score': f1
    }

def plot_training_history(history):
    """Plot training history."""
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    
    # Loss
    axes[0, 0].plot(history.history['loss'], label='Training Loss')
    axes[0, 0].plot(history.history['val_loss'], label='Validation Loss')
    axes[0, 0].set_title('Model Loss')
    axes[0, 0].set_xlabel('Epoch')
    axes[0, 0].set_ylabel('Loss')
    axes[0, 0].legend()
    
    # Dice coefficient
    axes[0, 1].plot(history.history['dice_coefficient'], label='Training Dice')
    axes[0, 1].plot(history.history['val_dice_coefficient'], label='Validation Dice')
    axes[0, 1].set_title('Dice Coefficient')
    axes[0, 1].set_xlabel('Epoch')
    axes[0, 1].set_ylabel('Dice Coefficient')
    axes[0, 1].legend()
    
    # Learning rate (if recorded)
    if 'lr' in history.history:
        axes[1, 0].plot(history.history['lr'])
        axes[1, 0].set_title('Learning Rate')
        axes[1, 0].set_xlabel('Epoch')
        axes[1, 0].set_ylabel('Learning Rate')
        axes[1, 0].set_yscale('log')
    
    # Remove empty subplot
    fig.delaxes(axes[1, 1])
    
    plt.tight_layout()
    plt.savefig(LOGS_DIR / 'training_history.png', dpi=150, bbox_inches='tight')
    plt.close()

def main():
    """Main training function."""
    print("ü§ñ Training Flood Detection U-Net")
    print("=" * 50)
    
    # Get list of available images
    available_images = []
    for filename in os.listdir(PREFLOOD_DIR):
        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):
            # Check if all required files exist
            if (POSTFLOOD_DIR / filename).exists() and (MASKS_DIR / filename).exists():
                available_images.append(filename)
    
    print(f"üìä Found {len(available_images)} complete image triplets")
    
    # Split data into train/validation sets
    train_images, val_images = train_test_split(
        available_images, test_size=VALIDATION_SPLIT, random_state=42
    )
    
    print(f"üèãÔ∏è  Training set: {len(train_images)} images")
    print(f"‚úÖ Validation set: {len(val_images)} images")
    
    # Create data generators
    train_generator = FloodDataGenerator(train_images, augment=True)
    val_generator = FloodDataGenerator(val_images, augment=False, shuffle=False)
    
    # Build model
    print("\nüèóÔ∏è  Building U-Net model...")
    model = build_unet()
    
    # Compile model
    model.compile(
        optimizer=optimizers.Adam(learning_rate=LEARNING_RATE),
        loss=combined_loss,
        metrics=[dice_coefficient]
    )
    
    # Print model summary
    model.summary()
    
    # Setup callbacks
    model_checkpoint = callbacks.ModelCheckpoint(
        str(MODELS_DIR / 'best_flood_unet.h5'),
        monitor='val_dice_coefficient',
        mode='max',
        save_best_only=True,
        verbose=1
    )
    
    reduce_lr = callbacks.ReduceLROnPlateau(
        monitor='val_loss',
        factor=0.5,
        patience=5,
        min_lr=1e-7,
        verbose=1
    )
    
    early_stopping = callbacks.EarlyStopping(
        monitor='val_dice_coefficient',
        mode='max',
        patience=10,
        restore_best_weights=True,
        verbose=1
    )
    
    # Train model
    print(f"\nüöÄ Starting training for {EPOCHS} epochs...")
    history = model.fit(
        train_generator,
        epochs=EPOCHS,
        validation_data=val_generator,
        callbacks=[model_checkpoint, reduce_lr, early_stopping],
        verbose=1
    )
    
    # Save final model
    model.save(str(MODELS_DIR / 'final_flood_unet.h5'))
    
    # Plot training history
    plot_training_history(history)
    
    # Evaluate model
    print("\nüìä Evaluating model performance...")
    metrics = evaluate_model(model, val_generator)
    
    print("\nüéØ Final Model Performance:")
    for metric, value in metrics.items():
        print(f"   {metric}: {value:.4f}")
    
    # Save metrics
    metrics_df = pd.DataFrame([metrics])
    metrics_df.to_csv(LOGS_DIR / 'final_metrics.csv', index=False)
    
    print(f"\n‚úÖ Training completed!")
    print(f"   üìÅ Best model saved to: {MODELS_DIR / 'best_flood_unet.h5'}")
    print(f"   üìà Training logs saved to: {LOGS_DIR.resolve()}")
    
    return model, history, metrics

if __name__ == "__main__":
    # Install albumentations if not available
    try:
        import albumentations as A
    except ImportError:
        print("Installing albumentations for data augmentation...")
        os.system("pip install albumentations")
        import albumentations as A
    
    model, history, metrics = main() 